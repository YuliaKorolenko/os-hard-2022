# os-hard-2022

***1.Определение операционной системы. Отличие между ОС и ядром ОС. Базовые понятия и концепции ОС. Общая архитектура ОС.***

***2.Системные вызовы. Особенности параметризации системных вызовов.***

***3.Режимы (modes) исполнения в ОС. Пространства памяти в ОС.***

***4.Монолитное и микро-ядро ОС — различия. Модульная структура ядра ОС.***

***5.Реализации мульти-обработки в ОС. Различие между кооперативным и вытесняющей (preemptive) мульти-обработкой. Кооперативные и вытесняющие ядра (на примере Линукса). Асимметричная и симметричная мульти-обработка (Asymmetric / symmetric multi-processing). Масштабирование ядра ОС по процессорам.***

***6.Общая структура кода ядра Линукса.***

7.Драйверы устройств в архитектуре Линукса.

***8.Управление процессами в ОС. Процессы и потоки. Переключение контекста и миграция задач по ядрам процесссора. Контекст процесса. Доступ к текущему процессу. Блокирование и пробуждение. Вытеснение задач в терминах контекста процесса. Системный вызов clone().***

***9.Пространства имен и контейнеры.***

***10.Прерывания (Interrupts). Исключительные ситуации (exceptions). Аппаратная концепция прерываний. Программируемый контроллер прерываний. Обработка прерываний в Линуксе. Контекст прерывания. Отложенные действия (deferrable actions). Мягкие запросы на прерывания (Soft IRQ). Тасклеты (Tasklets). Рабочие очереди и таймеры.***

***11.Что такое управление памятью (memory management). Адресные пространства памяти — физическое и виртуальное. Таблицы трансляции виртуальных адресов. Контексты исполнения. Стеки пользовательского кода, кода ядра и кода прерываний. Страничная организация памяти и вытеснение страниц на диск.***

12.Виртуальные и физические адреса. Устройство управления памятью (MMU). Буфера кэширования трансляции адресов (TLB). Адресные пространства на примере архитектуры ARM. Количество бит в адресе и деления адресов. Линейное отображение адресов. Нелинейное (произвольное) отображение адресов. Фиксированное отображение линейных адресов. Временное/быстрое отображение адресов (страницы в ядре). Постоянное отображение адресов.

13.Управление физической памятью. Зоны памяти. Неоднородный и однородный доступ к памяти. Кэш страниц в файловом доступе. Выделение физической памяти. kmalloc() & kfree(). Buddy-алгоритм выделения памяти.

14.Подход к SLAB выделению маленьких фрагментов памяти. Реализация SLAB. Кэши и SLAB.

15.Управление виртуальной памятью. Анонимная память (анонимное отображение памяти). Переиспользование (reclaim) памяти. Дефрагментация (Compaction) памяти. Обработка нехватки памяти (Out Of Memory Killer). Обработка обращения к отсутствующей странице (page fault). Типы/виды page fault. Влияние page fault на производительность.

16.Виртуальная файловая система и управление блочным вводом-выводом.

17.Абстракции файловой системы. Пример простой файловой системы (структура на диске). Операции файловой системы. Кэширование структур данных файловой системы.

***18.Синхронизация — основные идеи и проблемы. Проблема состояния гонки (race condition). Как избегать состояния гонки. Атомарные операции. Спинлоки. Когерентность кэша в многопроцессорных системах. Протоколы когерентности кэша. Вытеснение используемых данных кэша (cache trashing). Синхронизация доступа к данным из контекста процесса и контекста прерывания. Мьютексы. Данные доступа на одном ядре (per CPU data). Упорядочивание доступа к памяти и барьеры. Чтение-копирование-обновление (Read-Copy-Update на примере списка).***

19.Санитайзеры программ. Санитайзеры от Гугла. Санитайзеры EFENCE, KFENCE. Санитайзер KASAN. Теневая память в KASAN. Красные зоны в KASAN.

 ***20.Сетевая функциональность — история и концепции. TCP/IP. Семейство протоколов в TCP/IP. Протокол ARP. Сетевой стек — диаграмма и уровни. Единицы данных в сетевых протоколах. Блок-схема: Передача — прием данных в сети. Сетевые устройства. IP сервисы: роутинг. Сокеты. Пример использования сокетов для клиент-сервер программ. Сетевой стэк в Линуксе.***

***21.Планирование ресурсов в ОС. Планировщик процессов. Типы планировщиков (по горизонту планирования). Диспетчер процессора/процессов. FIFO планировщик. Метрики планирования в мобильной ОС.***

***22.Абстракции/концепции планирования. Абстракция/концепция аппаратуры/»железа»/устройства для планирования. Абстракция/концепция задачи/процесса для планирования.***

***23.История планировщиков в ядре Линукс. Планировщик CFS. Планировщик процессоров/процессов и формулы потребления энергии. Потребление энергии процессором/памятью. Абстракции управления потреблением энергии.***

***24.Что такое DVFS, зачем оно нужно. Архитектура big.LITTLE в контексте планирования процессов. EAS — что это такое, основные принципы. Отслеживание нагрузки для планирования процессов. EAS PELT/WALT. C & P, CC & PC состояния процессора. Управление P состояниями со стороны ОС. Масштибирование производительности в ядре Линукс. Управление частотами в ядре Линукс. Что такое CPUFreq, CPUIdle и гувернеры.***

***25.Распределенные системы. Оверлейные сети. Понятие middleware. ОС и middleware. Цели дизайна распределенной ОС. Ошибочные предположения в дизайне распределенной системы. Высокопроизводительные распределенные системы. Кластерные архитектуры. Grid-архитектуры. Облачные архитектуры. Проникующие системы (pervasive systems). Вездесущие (Ubiquitous) системы.***

***26.Мобильные ad hoc системы. Концепции архитектуры распределенных систем. Архитектурные стили для распределенных систем. Объектные архитектуры. Распределенные и удаленные обьекты. Ресурсно-ориентированные архитектуры. Архитектура Издатель-Подписчик. Структурированные peer-to-peer системы. Неструктурированные peer-to-peer системы: обмен сообщениями. Иерархические peer-to-peer системы.***

***27.Основы программирования для мобильной ОС. Что такое ADB и как им пользоваться. Измерение производительности приложения в инструкциях и циклах. Что такое perf и как им пользоваться.***

## Лекция 1

***Билет 1.*** Определение операционной системы. Отличие между ОС и ядром ОС. Базовые понятия и концепции ОС. Общая архитектура ОС

***Билет 2.*** Системные вызовы. Особенности параметризации системных вызовов.

***Билет 3.*** Режимы (modes) исполнения в ОС. Пространства памяти в ОС.

***Билет 4.*** Монолитное и микро-ядро ОС — различия. Модульная структура ядра ОС.

***Билет 5.*** Реализации мульти-обработки в ОС. Различие между кооперативным и вытесняющей (preemptive) мульти-обработкой. Кооперативные и вытесняющие ядра (на примере Линукса). Асимметричная и симметричная мульти-обработка (Asymmetric / symmetric multi-processing). Масштабирование ядра ОС по процессорам.

***Билет 6.*** Общая структура кода ядра Линукса.

Операционная система == ОС
----

Операционная система (ОС) — это системное программное обеспечение, управляет компьютерным оборудованием, программными ресурсами и предоставляет общие услуги для компьютерных программ.

Отличие между ОС и ядром ОС.
----

Ядро это прослойка между приложениями и оборудованием системы(аппаратным обеспечением). Это также первая программа, которая запускается в системе. Она же завершается только в момент завершения работы всей системы.

Базовые понятия и концепции ОС.
----

Системные вызовы - форма APi((Application Programming Interface) — описание способов взаимодействия одной компьютерной программы с другими.), функции с возможно пустым числом параметров, и с возвращаемыми значениями. Редко меняется интерфейс, потому что придется переписывать все приложения, а внутри меняется достаточно часто.

Сам код ядра можно логически разделить на код ядра и код драйверов устройств. Код драйверов устройств отвечает за доступ конкретных устройств, в то время как основной код ядра является общим. Core ядра может быть дополнительно разделена на несколько логических подсистем (например, доступ к файлам, сеть, управление процессами и т. д.)

Приложения работают в пользовательском пространстве. Через системные вызовы они обращаются к функциям ядра. Ядро и драйверы девайсов образуют пространство ядра. Уже они взаимодействуют с аппаратной частью. В дополнение, к процессору применимо понятие режима гипервизора. Он используется для запуска виртуальных машин.

Общая архитектура ОС
----

вот тут лежит таблица с кодом для системных вызовов rch/arm64/kernel/entry.S

![image](https://user-images.githubusercontent.com/79725120/213920139-67c00537-e246-419d-b44e-9e340c4697b8.png)


![image](https://user-images.githubusercontent.com/79725120/213896456-b2b688be-6ebf-4157-ae32-238408a33b62.png)

 

Режимы (modes) исполнения в ОС. Пространства памяти в ОС.
----

Запуск процесса в режиме ядра (kernel mode) требует больше привилегий, по сравнению с пользовательским (user mode). Пространство ядра является защищенным. Приложения не могут обращаться в него напрямую, в отличие от обратного. 

Есть различные режимы :
1. режим ядра L1
2. режим пользователя L0
3. режим гипервизора - для виртуальных машин
4. режим устройств, fermware

У режима ядра очень много возможностей, можно сломать! В режиме пользователя например нельзя некоторыми прерываниями пользователя.

Ядерный взгляд на память (недоступно с точки зрения приложений) и пользовательский

Монолитное и микро-ядро ОС — различия. Модульная структура ядра ОС.
----

Монолитное ядро – только логическое разделение подсистем. КАждая часть ядра имеет доступ к памяти других частей ядра. Могут испортить в других модулях. Само ядро работает быстро.

![image](https://user-images.githubusercontent.com/79725120/213921734-6e53adfa-5124-444f-84c1-cd16d02dac78.png)

Микро-ядро – С развитием была предложена альтернатива. Доступ ограничен к памяти.  многие подсистемы запускаются в виде сервисов в пользовательском пространстве, имеет защиту доступа к памяти между сервисами. Если сломается один блок в ядре слоамется, микроядро может обнаружить проблему и перезапустить. Скорость работы намного ниже. Мало гре применяется.

![image](https://user-images.githubusercontent.com/79725120/213921826-fdd7d5f9-3740-49d3-803d-768bfbcdc245.png)

Гибридные системы – основные службы выполняются в режиме монолитного ядра.  Можно обеспечивать какую-то безопасность и не терять в скорости сильно. Компоненты могут быть включены или отключены во время компиляции. Поддержка загружаемых модулей ядра (во время выполнения). Можно организовать ядро в логические независимые подсистемы. Строгие интерфейсы, но с низкими затратами на производительность: макросы, встроенные
функции, указатели функций. Легче программировать, если разделено.

Сплетня: Был спор между гибридным и монолитным ядром.

Монолитное ядро является модульным. Компоненты могут подключаться  или отключаться во время компиляции. Поддерживает загружаемые модули ядра (во время выполнения). Организует ядро в логике, содержит независимые подсистемы. Строгие интерфейсы, но с низкой производительностью.

Мультипроцессорность. Различие между кооперативным и вытесняющей (preemptive) мульти-обработкой. Кооперативные и вытесняющие ядра (на примере Линукса).
----

ОС, поддерживающая параллельное («одновременное») выполнение нескольких процессы. Реализовано путем переключения между запущенными процессами, чтобы позволить процессу сделать что-то полезное
Реализации могут быть:
1. Cooperative (non-preemptive) — процессы взаимодействуют для достижения многозадачности. Процесс запустится передаст управление ЦП ОС, которая затем запланирует другой процесс. Процессы договариваются друг с другом. Я пишу код, он поработает, потом отдасть время ядра другому.
2. Preemptive — ядро устанавливает ограничения по времени для каждого процесса, чтобы все процессы Иметь шанс. Каждому процессу разрешено запускать квант времени (например, 100 мс) после который, если он все еще запущен, прерывается и назначается другой процесс.

Операционная система реализует механизм мульти-обработки процессов. Он заключается в переключении между ними.

Кооперативный подход – процессы объединяются для решения задач. Сначала дается доступ одному из них, остальные ждут пока тот не отдаст контроль обратно ОС. Она назначает следующий процесс.

Вытесняющий подход – ядро определяет, какое время исполнения дать каждому процессу. Когда лимит исчерпывается, задача вытесняется и на ее место назначается новая.

Ядро (non-preemptive), свойства :
1) процесс работает до тех пор, пока не решит, что ему нужно остановиться и отдать время другому.
2) для реального времени плохо, потому что нет ниакой гарантии времени отлика
3) выбор задад контролируется процессором
4) чаще не рарешается остановка времени
5) разделяемые данные часто присутствуют, нужно использовать семафоры
6) легче разработывать код, так как мы уверены, что нас не прервут, но нам самим надо думать, когда нужно прерывать рограмму.
7) менее надежно и полезно, все переходят к преемтив, почему-то менее надежно

Ядро с возможностью вытеснения (preemptive kernels) – процесс может быть вытеснен, даже если он исполняется в режиме ядра (kernel mode). Также верно и обратное. Линукс перешел на preemptive ядра, тк
1) любой процесс может быть приостановлен в любой момент времени
2) временный отклик детерменированный, так как планировщик все знает
3) не требует семафоров
4) труднее разрабатывать, но более надежно

Асимметричная и симметричная мульти-обработка (Asymmetric / symmetric multi-processing). Масштабирование ядра ОС по процессорам.
----

![image](https://user-images.githubusercontent.com/79725120/213924269-0438d273-3551-479a-809c-0335141ad0ac.png)

![image](https://user-images.githubusercontent.com/79725120/213924304-00f87dd2-b954-452f-9b06-2695f086c70a.png)

Симметричная позволяет использовать процессоры и ядра как им удобно.

Ассиметричная мультиобработка – выделяется отдельное ядро для запуска процессов в kernel mode. Остальные на любых оставшихся. Симметричная – не зависимости, где исполнять задачу.

Успех увеличения количества ядер зависит от возможности повысить производительность, наличию наименьшего числа блокировок (locks), использованиия алгоритмов с минимальной сложностью.

Насколько хорошо масштабируется производительность в зависимости от количества ядер. По возможности используйте алгоритмы без блокировки. Используйте мелкозернистую блокировку для областей с высокой конкуренцией. Обратите внимание на сложность алгоритма

Память
----

размер страницы 4 килобайта, Виртуальная память видится непрерывно. Ядро может использовать виртуальную и физическую память. Аллокаторы иногда не могут получить непрерывный кусок физической памяти.

48 бит для адрессации

![image](https://user-images.githubusercontent.com/79725120/213926769-9d60acb1-2e76-4c17-b647-034e58f180e6.png)

 есть аллокатор в юзер саэйсе и в ядре
 
 Как происходит отображение с виртуальной памяти на физическую?
 
 с помощью таблиц трансляции из 512 элементов. 4 таблицы для косвенной адрессации. 48 битный адресс, используются 9битные кусочки для того чтобы выбрать ячейку таблицу трансляции на определенном уровне. Операционная система следит за таблицами, за виртуальной памятью.
 
 Контест исполнения у процесса:
 
 1)  содержимое регистров
 2)  содержимое стека
 3)  содержимое кучи

кеш процессора

Зачем он? Если есть много процессов и ос какие-то процессы приостанавливает, какие-то перезапускает, то хочется, чтобы процесс мог возобновить свою работу.
 
Мехнизм прерывания - процесс нажатия на экран/клавишу, информация о котором передается и быстро обратаьывается и данные передаются нужному процессу.

swaping(подкачка) - вытеснение памяти на диск для освобождения, потом чтение ее
Пейджинг(paging) — это процедура выделения памяти, при которой разным несмежным блокам памяти назначается фиксированный размер. Размер обычно составляет 4 КБ. Пейджинг всегда выполняется между активными страницами.

Общая структура кода ядра Линукса.
----

fs - Файловая   система  определяет, как файлы именуются   , хранятся   и извлекаются   из  устройства хранения.

Каждый раз, когда вы открываете файл на своем компьютере или смарт-устройстве, ваша операционная система использует внутреннюю файловую систему, чтобы загрузить его с устройства хранения.

Или когда вы копируете, редактируете или удаляете файл, файловая система обрабатывает его скрыто.

Всякий раз, когда вы загружаете файл или получаете доступ к веб-странице через Интернет, также задействована файловая система.

![image](https://user-images.githubusercontent.com/79725120/213927937-930e5d6a-89da-4afa-a302-8c0525b02c89.png)

![image](https://user-images.githubusercontent.com/79725120/213927962-421cd6a5-68c2-4044-9600-24c1e9b809fa.png)

## Лекция 3

***Билет 8***.Управление процессами в ОС. Процессы и потоки. Переключение контекста и миграция задач по ядрам процесссора. Контекст процесса. Доступ к текущему процессу. Блокирование и пробуждение. Вытеснение задач в терминах контекста процесса. Системный вызов clone().

Процесс – это программа на этапе исполнения. Содержит набор из адресного пространства, один или больше потоков, открытые файлы, сокеты, семафоры, области общедоступной памяти и тд.

Потоки – это части программы на этапе исполнения. Процесс может делать сразу несколько частей работы одновременно используя соответствующее количество потоков. Каждый поток в едином процессе делит ту же область памяти, что и другие. Каждый поток имеет свой стек (место, где приватные переменные могут хранится) и вместе со значениями регистров они образуют состояние потока. У каждого потока есть свой набор регистров. У каждого потока есть доступ к контексту процесса. Ядро клонирует потоки.

Файлы - один из механизмов взаимодействия процессов. Например, один процесс в файл что-то пишет, другой читает.

![image](https://user-images.githubusercontent.com/79725120/213933425-e6142161-4682-41d4-9e16-f3c811211c6a.png)

Разница процесса и потока. Каждый поток разделяет адресное пространство. Каждый поток может доступится в адресное пространство другого потока. А у процессов разное, букально есть shared memory regions, чтобы был доступ у двух процессов.

Контекст процесса - содержимое адресного пространства,  это все данные, которые создаются, изменяются и сохраняются во время выполнения процесса. Контекст используется кодом в режиме пользователя (является частью процесса) и в режиме ядра (исполнение системного вызова).

![image](https://user-images.githubusercontent.com/79725120/213934818-f01083c2-ab13-41e3-8bde-3f2123c220b4.png)

Прежде чем произойдет переключение контекста процесса, необходимо перейти в пространство ядра (не важно, при системном вызове или прерывании). В этот момент регистры (использовавшиеся в пространстве пользователя) сохраняются на стеке ядра системы. После этого, в некоторый момент, будет вызван планировщик, который решит, что переключение контекста должно произойти.

Блокирование текущего потока является важной операцией для организации планировщика. Применяются следующие опреации: текущее состояние потока помечается как прерванное, задача добавляется в очередь ожидания, планировщик назначает на исполнение новую задачу из очереди готовых, происходит переключение контекста.

Пробуждение потока берет задачу из очереди ожидания и назначает ей состояние готовой к исполнению.

Доступ к процессу это частая операция. Более 90% системных вызовов используют его. Во-первых существует макрос, который предоставляет доступ к struct task_struct. Во-вторых для поддержки быстрого доступа в многоядерных системах существет переменная для каждого ядра, хранящая указатель на текущую struct task_struct.

Новый поток или процесс создается с помощью системного вызова clone(). В параметрах можно указать, какие именно ресурсы будут общими между создаваемым и родительским потоками.

Системные вызовы. Особенности параметризации системных вызовов.
----
Это есть в тетрадке 

Системные вызовы – часть API ядра. Это граница между исполнением процессов в пользовательском режиме и режиме ядра.

Процесс исполнения – идентифицируется системный вызов, происходит переход в kernel mode, исполняется запрос, переход в user mode, достается результат вызова. Передача параметров происходит через регистры ядра (в том числе и номер системного вызова). В момент изменения режимов, происходит сохранение регистров ядра и замена user stack <-> kernel stack.

Так как параметры определяются в пользовательском режиме, системе приходится каждый раз проверять их корректность. Некоторые условия: никогда нельзя предоставлять указатели в пространство ядра, проверять корректность указателей. 
Есть проверка указателей, поэтому нельзя передать указательна кернел спэйс. То есть, если ядро хочет отдать какие-то данные user space, то оно сначала копирует эти данные в user space, а потом дает указатель.

Обработчики системных вызовов со стороны ядра это таблица с кусочками кода обработчка. На нулевом адресе находятся инструкции для системного вызова с номером 0, потом со смещением для первого и тд.

Начальный адрес таблички находится в одном из регистров VBAR_EL3, VBAR_EL2 и VBAR_EL1

вот тут лежит таблица с кодом для системных вызовов rch/arm64/kernel/entry.S

каждый обработчик имеет длину в 32 инструкции, каждая инструкция 4 байта. Минусы для такого подхода хранения, что некоторые байты  не хранят(это арм), а в xv6 не так. Но арм из-за этого выигрывает в скорости.

![image](https://user-images.githubusercontent.com/79725120/213931930-5d1fbc10-42c3-4b32-8bfd-1714beda8f85.png)

Пространства имен и контейнеры.
----

Namespace - функциональность ядра линукса, которая позволяет объединять схожие ресурсы. Используются для ограничения доступа ресурсов разным проццесорам. Один и тот же ресурс может входить в разные namespace. Примерами таких ресурсов являются идентификаторы процессов, имена хостов, идентификаторы пользователей, имена файлов и некоторые имена, связанные с сетевым доступом, и межпроцессного взаимодействия. Процессы могут создавать дополнительные пространства имен и присоединяться к другим пространствам имен. Практическая польза от нейм спейса - можно использовать разные версии библиотек и приложений.

Пространства имен определяют связи между набором процессов и набором ресурсов. Ресурсы могут существовать в нескольких пространствах (примеры таких ресурсов: идентификатор процесса, имя хоста, идентификатор пользователя, названия файлов). Изначально Линукс создает единое пространство имен, которое используется каждым процессом. Далее, процессы могут создавать дополнительные и присоединяться к уже существующим.

История
1. первоначально использовались в лабораториии план 9
2. появились в 2002 в линуксе 

Контейнер - легковесная виртуальная машина. Загнать про приложения, которые используют например разные версии питона, но мы хотим запускать в одной операционной. А в контейнере может записать, что в одном используется версия настоящего ядра, а в другом контейнеер пишем, что предыдущей версии.

Контейнеры – это форма облегченных виртуальных машин, которые совместно используют один и тот же экземпляр ядра. Пример – docker. Контейнеры построены поверх нескольких функций ядра, одной из которых являются пространства имен. Они позволяют изолировать различные ресурсы, которые в противном случае были бы видны всей системе.

Группы управления: для иерархической организации процессов и распределения системных
ресурсов (по иерархии) специальным и настраиваемым образом.

##Лекция 4

***Билет 10*** Прерывания (Interrupts). Исключительные ситуации (exceptions). Аппаратная концепция прерываний. Программируемый контроллер прерываний. Обработка прерываний в Линуксе. Контекст прерывания. Отложенные действия (deferrable actions). Мягкие запросы на прерывания (Soft IRQ). Тасклеты (Tasklets). Рабочие очереди и таймеры.

Прерывание
----

Прерывание — это событие, которое изменяет нормальный поток выполнения программа и может быть сгенерирована аппаратными устройствами или даже CPU.

Когда происходит прерывание, текущий поток выполнения приостанавливается и запускается обработчик прерывания. После запуска обработчика прерывания возобновляется предыдущий поток выполнения. Если прерывание аппаратное, то про предыдущий поток выполнение можно забыть, потому что система просто перезапускается.

Виды прерываний:

1. синхронные - генерируются во время выполнения инструкций, деление на 0. Также называют exceptions. Процессор сам обрабатывает.
2. асинхронные - оно генерируется внешним событием, это может устройство ввода-вывода, например мышка или клавиатура


1. маскируемые ( можно их проигнорировать, передаются через канал INT от interrupt)
2. non-maskabke ( нельзя не обрабаьывать, например жеский диск подаст прерывание, что сломался, через канал NMI)

Exceptions:
1. fault - обычно возникает перед исполнением инструкции. Его нужно исправить, адрес вызванной инструкции сохраняется, потом возвращается к этой же инструкции. И можно продолжать работу.
2. trap - ловушка.
3. abort - прекращение исполнения, обычные ошибки, как exception в с++

![image](https://user-images.githubusercontent.com/79725120/213937961-7ae6c82f-5d87-47bb-ba24-cf02c4e9cd50.png)

Прерывания могут обрабатываться PIC(proggramable interrapt controller)
----

Имеет множество портов, чтобы обмениваться информацией с PCU, существует для разгрузки процессора, превращает сигналы в удобную для процессора форму.

Порядок действий:

1. Устройство подает прерывания
2. Сигнал подается на один из входов
3. Контроллер преобразует сигнал в номер вектора прерываний(по сути команды упорядоченные) и передает в канал
4. Процессор начинает обработку

Есть возможность маскровать прерывания на уровне устройства или контроллера.

Контекст прерывания
----

У прерываний может быть приоритеты(в линуксе не используется)

Есть 3 фазы прерываний
1. критическая. Все важные дейсвия выполняются на данной фазе. Если только критические, то прерывание завершено. Эту фазу обрабатывает ядро.
2. непосредстсвенная. Эта фаза может обрабатываться драйвером.
3. отложенное. Самые неважные. Вот тут уже прерывания разрешены прерывания на локальном устройстве. Обрабатывается в ядре.

Контекст прерывания, состоит из регистров. Если пришло другое прерывание, то контекст сохраняется, обрабатывается более приоритетное прерывание, потом идет в текущее, достает стек регистры, работаем.

Свойства кода, который исполняется в контексте прерывания:
1) Нет хорошо определенного контекста процесса
2) Во время прерывания нельзя сделать свитч процессов, послать обработчик прерывания в сон.

![image](https://user-images.githubusercontent.com/79725120/213939507-49f77ac4-ff17-4463-8783-b6bffa46ddf0.png)

 Отложенные действия (deferrable actions).
 ----
 
 Это такие действия, которы мы может исполнять уже сильно после обработки прерывания. Складываются в очередь какую-то и начинаются исполняться. Либо они используют контекст прерывания, либо контекст процесса. 
 
 Если прерывания требует многих действий, мы можем сказать, что ои неважные и отложить. Но лучше все равно их делать поменьше. У таких действий есть свой API:
 initialize, activate, schedule, mask/disable, unmask/enable (инициализации экземпляра, активации или планирования действия и маскировать/отключать и размаскировать/включать выполнение функции обратного вызова. Последний используется для целях синхронизации между функцией обратного вызова и другими контекстами.) Нужно, чтобы синхронизировать колбэки и контекст процесса.
 
 Мягкие запросы на прерывания (Soft IRQ)
 ----
 Механизм, который позволяет реализовать отложенные действия еще одним способом. Работает в контексте прерывания. То есть может использовать те переменные данные, которые были в нашем прерывании. Может параллельно работать на нескольких ядрах.
 
   Soft IRQ APIs:
1) initialize: open_softirq()
2) activation: raise_softirq()
3) masking: local_bh_disable(), local_bh_enable()


После активации функция обратного вызова do_softirq() запускается либо:
• после обработчика прерывания или
• из потока ядра ksoftirqd (его задача исполнять такие омягкие прерывания, не тратя активно проццессорное время, чтобы было разумное время отклика)
 
 Тасклеты (Tasklets)
 ----
 
 Следующий уровень абстракции, реализован на основе предыдущей функции soft IRQ. Если их много собралось, то они разбрасываются на разные ядра. Тоже работают в контексте прерывания, создаются динамически(типо в куче, создаются а потом освобождаются)
 
   Tasklets API:
• initialization: tasklet_init()
• activation: tasklet_schedule()
• masking: tasklet_disable(), tasklet_enable()
 
 Рабочие очереди и таймеры
 ----
 
 Рабочие очереди уже в контексте процесса.
 
 Workqueues API:
• init: INIT_WORK
• activation: schedule_work()

 таймеры - функции, которые помогают обрабатывать, выполнять какие-то отложенные действия.
 
  Timer API:
• initialization: setup_timer()
• activation: mod_timer(


***Билет 18*** Синхронизация — основные идеи и проблемы. Проблема состояния гонки (race condition). Как избегать состояния гонки. Атомарные операции. Спинлоки. Когерентность кэша в многопроцессорных системах. Протоколы когерентности кэша. Вытеснение используемых данных кэша (cache trashing). Синхронизация доступа к данным из контекста процесса и контекста прерывания. Мьютексы. Данные доступа на одном ядре (per CPU data). Упорядочивание доступа к памяти и барьеры. Чтение-копирование-обновление (Read-Copy-Update на примере списка).

Синхронизация — основные идеи и проблемы.
----

многоядерные, поэтому проблемы синхронизации. 

Один из способов избежать проблем с синхронизацией - алгоритмы лок фри, атомарные операции.

Проблема состояния гонки - два потока исполняются параллельно и один из проццесов может вытеснить другой в результате прерывания. когда процессы или потоки используют разделяемые переменные. 

![image](https://user-images.githubusercontent.com/79725120/213944974-ebed7a21-3566-4594-aea1-a891f69c7215.png)

пример гонки

откуда получается?
1) когда есть вытестнение ( прерывания, засыпает поток)
2) когда параллельно исполняются потоки 

![image](https://user-images.githubusercontent.com/79725120/213945232-01001868-c8a6-48ba-86a2-b03ec6d12db6.png)

как избежать?

определить участок кода с разделяемыми переменными, можно использовать несколько приемов
1) сделать секцию атомарной
2) отключить вытеснение во время критической секции (например, отключить прерывания, обработчики нижней половины или вытеснение потока)
3) использовать исключающий доступ к критической секции (например, использовать спин-блокировки или мьютексы для разрешить только один контекст или поток в критической секции.

![image](https://user-images.githubusercontent.com/79725120/213945307-b1000219-64a3-4e3f-a709-84a681d4f2a4.png)

![image](https://user-images.githubusercontent.com/79725120/213945338-a26874c7-ba54-480a-be05-75b9f3d496bc.png)

 проблемы с многоядерными системаи
 
 Спинлок 
 ----
 
 ограничитель с вращениями. Мы мможем использовать атомарную операцию, проверить атомарно, и в зависимости от значения инкрементировать. Если ноль — спинлок свободен, и его можно захватить. Если не ноль — спинлок заперт, и нить, которая желает его захватить, будет ждать, крутясь (spin — вращение) в небольшом цикле непрерывной проверки освобождения спинлока. 
 
 Кеши в параллельном исполнении
 ----
 
 ![image](https://user-images.githubusercontent.com/79725120/213945510-852ad30d-7640-4d6e-903b-b1a4f2d0caa8.png)
 
 Если нет синхронизации между кэшами, в итоге разные значения.
 
 Cache coherency (когерентность кешей) - если одна и та же переменная находится в двух разных кэшах, и в одном из кэшах оно изменяется, то на аппаратном уровне, изменение переносится в другой кэш. Даже если переменные находятся в одной кеш линии, но в одном ядре меняется только переменная а, а в другом только б то все равно синхронизация будет происходит - false sharing.
 
 Есть некоторые специальные барьерные инструкции, которые помогут синхронизовать кэш.
 
 Протоколы когерентности кешей
 ----
 
 Bus snoping
 ----
 когда все операции по изменению памяти отслеживаются кэшами, и на аппаратном уровне предпринимаются действия, чтобы они были синхронизированы. Вот эта штука попроще, но плохо работает, когда количество ядер выходит за пределы 32-64.
 
 Directory based
 ----
 есть специальная сущность, в которой отслеживается состояние кешей, используется, чтобы отслеживает изменение
 
 MESI cache coherency protocol
 ----
 
 Именуется по именам состояний строки кэша: Modified, Exclusive, Shared и Invalid.
1) Modified: принадлежит одноядерному и грязному
2) Exclusive: принадлежит одному ядру и чиста
3) Shared: общий для нескольких ядер и чистый
4) Invalid: строка не кэшируется

 Когда данные записываются в кэш, они сразу записываются в память
 
Invalid -> Exclusive:запрос на чтение, все остальные ядра имеют строку Invalid; линия загружена
из памяти
• Invalid -> Shared: в запросе хотя бы одно ядро имеет строку в Shared или Exclusive;
строка загружается из кеша-соседа
• Invalid/Shared/Exclusive -> Modified: написать запрос записи; все остальные ядра делают строку недействительной, сбрасываем в память 
• Modified -> Invalid: запрос записи из другого ядра; линия сбрасывается в память

![image](https://user-images.githubusercontent.com/79725120/213946243-c9bd0751-343b-49a6-9b01-a8d51e051f4c.png)


## Лекция 5

Вытеснение используемых данных кэша (cache trashing). Синхронизация доступа к данным из контекста процесса и контекста прерывания. Мьютексы. Данные доступа на одном ядре (per CPU data). Упорядочивание доступа к памяти и барьеры. Чтение-копирование-обновление (Read-Copy-Update на примере списка).

Когда при условии прерывания нам нужен доступ к контексту процесса, может возникнуть дедлок. В многоядерной очень легко может возникнуть дедлок. Так как процес выгружен и остановлен, а у него спинлок, прерывание пытается взять этот спинлок и не может.

Как избежать проблему?

Чтобы избежать этой проблемы:
• В контексте процесса: отключить прерывания (можно это сделать на данном ядре и прерывани просто будут исполнятся на других ядрах) и получить спин-блокировку; это защитит обоих против прерывания или других условий гонки ядер ЦП
• spin_lock_irqsave() и spin_lock_restore() объединяют два операции. Такая же проблема в других вадах прерываний софт_ркью. Но там есть специальное апи для избежания этого.

• В контексте прерывания: взять спин-блокировку; это защитит от условий гонки с другие обработчики прерываний или контекст процесса, работающий на другом
процессоры

Еще один источник дедлоков - preemtion. Останавливаем процесс, а у него взят спинлок. Можно либо отключить преемтион, либо использовать мьютексы.

Мью́текс 
----

(англ. mutex, от mutual exclusion — «взаимное исключение») — примитив синхронизации, обеспечивающий взаимное исключение исполнения критических участков кода[1]. Классический мьютекс отличается от двоичного семафора наличием эксклюзивного владельца, который и должен его освобождать (т.е. переводить в незаблокированное состояние)[2]. От спинлока мьютекс отличается передачей управления планировщику для переключения потоков при невозможности захвата мьютекса.  Если процесс хочет взять мьютекс, то он ставится в очередь и ожидает, пока он освободится, не использует cpu-cicle. Более высокая задержка, потому что сложнее устроен. Мьютексы можно использовать в юзерспейсе, но нужно иметь ввиду, что за ним стоит системный вызов.

Данные доступа на одном ядре (per CPU data).
----

Можно использовать per CPU data, для каждого процессора есть свои данные, есть доступ только процессам ядра, понятно, что не будет случая, что один процесс что-то пишет, а другой читает, пока первый не записал.

Упорядочивание доступа к памяти и барьеры

![image](https://user-images.githubusercontent.com/79725120/213947265-60e1d50f-15d3-4a1e-b449-2b49e0cde942.png)

часто так делаеют компиляторы, переупорядоучивают код, между которыми нет связи, это нужно, чтобы лучше использовать конвееры

тут про го ту или джамп. Есть операция, нам пока не нужно ее исполнять, мы по нужному адресу переходим, и все в кеш загружаем, те операции, которые потом исполним, и дальше тусуемся, а в кеше можно подглядеть.

Ускоряется, но может произойти утечка данных, потому что процесор выниает что-то из памяти и кладет в кеш, можем вы

Упорядочивание доступа к памяти и барьеры.
----
 Барьер - когда испоняются инструкции барьеров, то процессор должен закончить все операции чтения и записи. Подразумевается, что после выполнения этой инструкции не будет каких-то переупорядоченные инструкций.
 
 Как показано выше, независимые операции доступа к памяти могут выполняться в произвольном порядке, что может стать проблемой для взаимодействия между процессорами или между процессором и внешним устройством. Требуется механизм для указания компилятору и процессору на необходимость соблюдения порядка.

Барьеры доступа к памяти являются таким механизмом. Они приводят к частичному упорядочиванию операций доступа к памяти по обе стороны барьера.

Барьеры записи.

Барьеры записи гарантируют, что все операции записи в память, для инструкций предшествующих барьеру, будут выполнены процессором до любой операции записи в память, для инструкций следующих за барьером, с точки зрения остальных компонентов системы.

Барьеры зависимости по данным.

Барьеры зависимости по данным — это ослабленная версия барьеров чтения. В случаях, когда две операции чтения выполняются таким образом, что вторая операция зависит от результата первой (например, первая операция получает адрес, из которого будет читать вторая), барьер зависимости по данным гарантирует, что данные по адресу второй операции чтения будут актуальными на момент выполнения этой операции.

Барьеры чтения.

Барьер чтения — это барьер зависимости по данным с гарантией, что все операции чтения, для инструкций предшествующих барьеру, будут выполнены процессором до любой операции чтения, для инструкций следующих за барьером, с точки зрения остальных компонентов системы.

Обобщённые барьеры доступа к памяти.

Барьер доступа к памяти гарантирует, что все операции чтения и записи, для инструкций предшествующих барьеру, будут выполнены до любых операций чтения или записи, для инструкций следующих за барьером, с точки зрения остальных компонентов системы.

Read-Copy-Update
----
есть уже запрограммированые структуры данных лок фри, всякие очереди 

расскажи логику на примере списка

![image](https://user-images.githubusercontent.com/79725120/213948095-bd2f16e5-46cf-467e-ab0f-d49ae1c21242.png)

***11.Что такое управление памятью (memory management). Адресные пространства памяти — физическое и виртуальное. Таблицы трансляции виртуальных адресов. Контексты исполнения. Стеки пользовательского кода, кода ядра и кода прерываний. Страничная организация памяти и вытеснение страниц на диск.***

12.Виртуальные и физические адреса. Устройство управления памятью (MMU). Буфера кэширования трансляции адресов (TLB). Адресные пространства на примере архитектуры ARM. Количество бит в адресе и деления адресов. Линейное отображение адресов. Нелинейное (произвольное) отображение адресов. Фиксированное отображение линейных адресов. Временное/быстрое отображение адресов (страницы в ядре). Постоянное отображение адресов.

Memory menegment
----

Присутсвует во всех современных операционных системах. Конструкция, которая поддерживается всех аппаратурой и операционной системой.

Мемори менедмент позволяет видеть намного больше памяти, чем есть в физической. Каждому приложению будет видно, что у них 16 гигабайт, хотя всего у нас столько. Для того, чтобы работало мемеори менеджмент, надо чтобы операционная система реализовала поддержку таблиц.

Любое приложение, которое исполняется работает с вирутальными адресами, которые уже потом преобразуются в физические.

Преимущество использования виртуальных адресов заключается в том, что они позволяют ОС управлять отображением памяти, которая представлены программному обеспечению.

ОС может управлять видимой памятью, виртуальным адресом (VA), по которому эта память видимо, и какой доступ разрешен к этой памяти.
Это позволяет ОС помещать приложения в песочницу (скрывая ресурсы одного приложения от другого).
приложение) и обеспечить абстракцию от основного оборудования.
Одним из преимуществ использования VA является то, что ОС может представлять несколько фрагментированных физических областей
память как единое непрерывное пространство виртуального пространства для приложения.
Виртуальные машины приносят пользу разработчикам программного обеспечения, которые не будут знать точных адресов системной памяти, когда
написание своего заявления.
Разработчикам программного обеспечения VA не нужно заботиться о физической памяти.
приложение знает, что это зависит от ОС и оборудования, которые должны работать вместе для выполнения адреса.
перевод.
На практике каждое приложение может использовать собственный набор виртуальных машин, которые будут привязаны к разным местоположениям в

Таблицы трансляций
----

![image](https://user-images.githubusercontent.com/79725120/213948991-7dd262a2-453c-4c66-93e0-3f2204a5e4c5.png)

У каждого процесса есть своя таблица трансляций, она является контекстом процесса, хотя не видна самамоу процессу.

таблицы трансляций заполняются операционной системой.

Устройство управления памятью (MMU).
----

Это аппаратная компонента, которая по сути делает вот эту трансляцию адресов.

В ней есть
1) подмодуль, который ходит по ээтим таблицам
2) TLB - Translation Lookaside Buffers (TLBs) Делает кеширование адресов, вместо обхождения таблицы, вынимаем адрес за один раз.

![image](https://user-images.githubusercontent.com/79725120/213949792-3294ee4f-dff9-47e3-9f0b-3c5e440b5d84.png)


то есть схема выглядит примерно так: приложение обращается по адресу х,  CPU видит это обращение, посылает запрос в mmu, mmu с помощью таблиц трансляции (которые до этого получило от ядра) переводит виртуальный адрес x в физический y, а потом контроллер памяти достаёт из памяти то, что лежит по этому физическому адресу. Устройство, которое достает - это контроллер памяти. но он достает предварительно заглянув в кэши ядра.

Адресные пространства
----

![image](https://user-images.githubusercontent.com/79725120/213949976-e1c65821-b343-477c-a4f1-67bee025319d.png)

виртуальное адресное пространсвто состоит из страничек, размера 4 кб. Тут упрощенная схема. 

![image](https://user-images.githubusercontent.com/79725120/213950166-d4851a5f-1003-4ef4-a11d-353b88f6c35e.png)

Виртуальный адрес состоит из 2ух частей = в старших битах адрес страницы + смещение в странице.

Первая часть используется для того, чтобы походить по страничкам, вторая часть просто приклеивается к физическому адресу.

![image](https://user-images.githubusercontent.com/79725120/213950357-f1b115e7-4265-4fef-a3c1-ba645ccb6da4.png)

Таблица первого уровня, куда мы обращаемся в первую очередь, она вынимает оттуда значение - либо это физический адрес, либо адрес в таблице следующего уровня. Всего уровни от 0 до 3. Если память фрагментирована, то уровней в таблицах становится больше.

Чем больше блок, тем на меньшее кол-во уровней надо спускаться, чтобы его найти. Большие блоки эффективнее для тлб.

![image](https://user-images.githubusercontent.com/79725120/213950734-2e570174-0272-4f3c-834e-e882a80694d6.png)

для каждого уровня, где 3 - фермвеер

Помимо нескольких виртуальных адресных пространств, AArch64 также имеет несколько физических адресных пространств.
(ПАС):
• Небезопасный PAS0
• Безопасный персональный доступ
• Realm PAS (только для Armv9-A)
• Корневой PAS (Armv9-A)

Каким образом идет отображение виртуальных адресов на физические в зависимости от от их ключей доступа
Небезопасный на небезопасный. Безопасный на небезопасный и безопасны Realm state: virtual addresses can map to Realm or Non-secure physical addresses• Root state: virtual address can map to any physical address space.

Размеры адресов
----

64 битные + в зер спейсе и в кернел спейсе свои адреса заранее, так проверяется, можем ли мы обратиться по данному адресу. 

![image](https://user-images.githubusercontent.com/79725120/213951197-272c5926-3873-47f3-b417-b15e234df0ef.png)

Есть определенные регистры, можно увеличить размеры юзер спейса и кернел спейса с помощью них.

В каждой таюлице трансляции находится 64 бита

![image](https://user-images.githubusercontent.com/79725120/213951404-fcb24482-7305-4b62-8475-98b9287dc7bd.png)

у арма есть свой термин - гранула трансляции.

TLB
----

кеш, может переиспользоваться, иногда нет, когда переключаемся на другой процесс, там новая тэйбл, затираем кеш.


## Лекция 6
Stract-page для управления физическими адресами, сируктура, которая описывает физическую страницу.

![image](https://user-images.githubusercontent.com/79725120/214000752-63798408-43b2-4abc-824d-a5262fcfea85.png)

![image](https://user-images.githubusercontent.com/79725120/213999811-3a5725ea-29c5-4c31-80b5-05835003167b.png)

![image](https://user-images.githubusercontent.com/79725120/214001433-d3e7d834-6b8f-4267-afe1-a9775e57d9f1.png)

рамер кеш строки 64 байт. У каждого слаба, если объекты не степень двойки, то есть неизмользуемая память в начале. В конце и вначале есть закрашенное пространство, которое помогает избегать false sharing

 Поскольку плиты начинаются на границах страницы,
вполне вероятно, что предметы внутри
несколько разных slab-страниц сопоставляются с
та же строка кэша, называемая «ложным разделением».
• Это приводит к менее оптимальному производительность аппаратного кэша.
• Путем смещения каждого начала первого объект внутри каждой плиты некоторым фрагмент строки аппаратного кэша размер, попадания в кэш процессора уменьшенный.

![image](https://user-images.githubusercontent.com/79725120/214002567-1dae8c46-53ec-4ee4-9a3a-cd4d6c54cd84.png)


Освобождение виртуальной памяти
• Удаление дескриптора области
• Освобождение памяти дескриптора области
• Обновление таблиц страниц для удаления области из виртуального адресного пространства.
• Сброс TLB для освобожденной области виртуальной памяти
• Освобождение физической памяти таблиц страниц, связанных с

### Лекция 7

Рабочий набор процессов (PWS)
• группа страниц физической памяти, выделенных в данный момент для определенного процесса
• ОС может записывать измененные страницы в выделенную область на запоминающем устройстве (обычно
известное как подкачка или пространство подкачки)
• ОС помечает неизмененные страницы как свободные (нет необходимости выписывать эти страницы
на диск так как они не изменились)
• Алгоритм LRU определяет, какие страницы могут быть удалены из PWS.


• Список бесплатных страниц для каждого процессора (ядра). Чаще вот эти убиваются 
• быстрый путь – нет синхронизации (почти)
• в структуре зоны, используемой для описания зоны управления памятью
• Когда система MM находится под нехваткой памяти, эти списки берутся (становятся пустыми)
• каждый ЦП теперь имеет два набора списков для хранения свободных страниц, один из которых используется в любой момент времени.
указанное время, а другой держится в резерве
• Атомарное сравнение и обмен используется для переключения двух списков, которые должны быть приняты системой MM.


Тут есть прикол, если мы хотим удалить странички, чтобы освободить память, то просто указатель со списками свободных страниц меняется на указатель пустого свписка, который уже был заранее создан.

• Общий список бесплатных страниц
• медленный путь, используемый, когда список для каждого ядра


Серьезные сбои страниц на обычных компьютерах с жесткими дисками могут иметь значительные последствия.
влияние на их производительность
• В среднем жесткий диск имеет
• средняя задержка вращения 3 мс
• время поиска 5 мс
• время передачи 0,05 мс/страница
• Таким образом, общее время пейджинга составляет около 8 мс (= 8000 мкс).
• Задержка строба адреса столбца (CAS), или CL, представляет собой задержку в тактовых циклах между
Команда READ и данные о моменте (1-е слово) доступны
• DDR3-1066 CL — 7 циклов, 1 цикл — 1,875 нс.
• DDR4-1600 CL — 12 циклов, 1 цикл — 1250 нс.
• Оптимизация производительности программ или операционных систем часто связана с уменьшением
количество ошибок страниц.
• Два основных направления оптимизации — сокращение общего использования памяти и
улучшение локальности памяти.
• Чтобы уменьшить количество ошибок страниц, разработчики должны использовать соответствующую замену страниц.
алгоритм, который максимизирует количество посещений страницы.
• Больший объем физической памяти также снижает число отказов страниц.

![image](https://user-images.githubusercontent.com/79725120/214019937-4388bead-b502-4e26-b5f6-cb325346b0cc.png)

![image](https://user-images.githubusercontent.com/79725120/214020281-2812a7cb-00ec-4e51-b27f-1d339bb53d10.png)


![image](https://user-images.githubusercontent.com/79725120/214022629-ded95ba3-e893-436a-98f1-0c976c765b59.png)

какую бы файловую систему мы не используем, она все равно сделана на virtual system switch, это давнишний api, который устоялся. Мы можем сделать свою отличающуюся, конечно, но тогда нужно повторить много уже сделанной работы 

Монтирование файловой системы - входные данные - partition, потом получаем указатель на дентри, Шаги: 1. проверить работает ли устройство, проверить параметры файловой системы, найти инод.

![image](https://user-images.githubusercontent.com/79725120/214023688-d688f745-6564-4b4c-bfab-195f464c32aa.png)

![image](https://user-images.githubusercontent.com/79725120/214023738-d726eaec-d253-4066-887e-ad2f16397637.png)

![image](https://user-images.githubusercontent.com/79725120/214023815-1104d17d-2f82-4a82-8dc2-eccb211f29c3.png)

![image](https://user-images.githubusercontent.com/79725120/214023925-21ecddf9-1efe-4c41-a4d6-e9a2732deac5.png)

inode cache - используют хэш-таблицу, индексируется при помощи хэш функции, берется суперблок. Кэш может освобождаться, если нужны страницы в физической памяти.

dentry cache - из этого кеша  есть ссылки в кеш айнодов

page cache - набор физ страниц, который сосответвуют оперделенному интервалу адресов, кеш для файлов, чтобы секономить время опять же.
 



## Лекция 9 (Билет 20)
____________
Сетевой стек

История и концепции
---

1.В 1962 Пол Баран описал военную инфраструктуру(сеть), которая должна была выдержать ядерный удар.

2.В 1967 рассмотрел в статье ситуацию о том, что датаграммы (кусочки) приходят в разном порядке. И как собрать сообщение из этих датаграмм? Нужно пронумеровать их, и знать количество датаграмм.

3.В 1970 Выложили стать про первую военную сеть ARPANET.

4.В 1973 была сделана первая сеть, которая обеспечивала полььзовательским приложениям надежную связь между компьютерами. Cyclade. Аналог TCP.

5. В 1981 DARPA(какая-то военная организация) опубликовала первую спецификацию Internet. Сообщение кроме разбиения на пакеты и datagram, они могут разбиваться еще на другие кусочки. Кода мы посылает большой пакет, меньше энергии, но больше вероятность, что пакет потеряется и его нужно будет отправлять еще раз. Если 10 маленьких пакетов, то потеряется например 1, мы его дошлем и по задержке будет намного эффективнее.
6. 1999 NAT, в локальной сети несколько устройств могут разделять один публичный адрес, тогда пространство адресов становится намного больше.
7. . 2015 Публикация рекомендации об очередности передачи пакетов.

СЕТЬ - система взаимосвязанных устройств, которые могут передавать информацию, делится ресурсами (принтеры, файлы, приложения). Каждое устройство имеет свой IP адрес, с помощью которого может посылать и получать сообщения, используя TCP/IP протокол(набор правил).

TCP - Transmission Control Protocol(Протокол управления передачей)
обмен данными меджу приложениями и сетью
если пакет был утерян, то по протоколу он будет послан еще раз

UDP - User Datagram Protocol
приложение должно само следить за потерянными пакетами, поэтому обеспечивает более быструю передачу

IP - Internet Protocol(интернет протокол)
обмен данными между компьютерами

DHCP - с роутерами

HTTP - браузеры

HTTPS - более безопасное взаимодействие с браузерами

FTP - файлы скачивать

NTP -  синхронизировать часы

SSL - безопасный обмен данными

TCP/IP
---

Определяют, как разбивать на пакеты, как они адресуются, как получать и разбирать. Они очень устойчивы и так как есть избыточность связи, то даже во время катастрофы будет работать.

IP адресс (192.68.20.50) <- адрес версии 4, 4ехбайтный.
TCP/IP V6 использует 128 бита. 2 последние байта остаются для локальный устройств. TCP/IP помогает получить локальному устройству адрес в сети.

Доменное имя - (www.itmo-global.com) всегда отправляется на DNS сервер, и там хранится соответсвие между всеми такими доменными именами и TCP/IP адресами. Обратно присылается числовой адрес. Потом начинается работа.

![image](https://user-images.githubusercontent.com/79725120/213421503-9a7e953f-3409-4b1e-a2b4-45d0717d7b56.png)

ARP (Address resolution protocol)
---

преобразует 32битный адрес в физический адрес(MAC адрес 48 бит, который есть у каждого устройства, с помощью его можно отследить твоё устройство, не передается в пакетах, но используется в сетевом стеке)

В роутере есть запись о соответсвии mac и tcp

есть несколько подходов
1. табличный
2. хэширование
3. обменом сообщениями


Сетевой стек в ядре линукс
---

Состоит из 5 слоёв.
![image](https://user-images.githubusercontent.com/79725120/213424274-7be17742-7eb5-45d5-8383-9ae5134c11c3.png)

1. Приложение. Через system call обращаемся к ядру. Приложение вызывет socket API.
3. В ядре есть транспортный уровень, на нем выбираем свой нужный протокол и данные. Тут рабираваются на пакеты. Тут добавляется TCP заголовок.
4. Следующий сетевой уровень знает, что происходит во внешней сети. И в зависимости от ее характеристик он может либо объединять пакеты, или наоборот разбивать их. Тут добавляется IP заголовок. 
5. Data Link, выравнивает фрагменты, делает их понятными для аппаратуры. Тут добавляется frame заголовок. Отправляет сетевой карте драйвера запрос об отправлении frame, которые лежат в очереди.
6. Драйвера этих устройств <- Физический уровень. Берет из очереди отправки пакетов через DMA
и отправляет frame через физическую сетевую карту. Прямой доступ к памяти (англ. direct memory access, DMA) — режим обмена данными между устройствами компьютера или же между устройством и основной памятью,

![image](https://user-images.githubusercontent.com/79725120/213426209-c33894c3-4ab5-41a0-ab81-a3d2fb5e4930.png)

![image](https://user-images.githubusercontent.com/79725120/213428849-dfe52ae6-5114-4911-bf6a-c543baf990b0.png)

![image](https://user-images.githubusercontent.com/79725120/213429085-e27eca08-d9f2-4b10-82a7-66be92342c81.png)

TCP пакеты 
UDP datagram делится на фрагменты, а фрагменты упакованы в frame

Сетевые устройства
---

gateway - компьютер, который соединяет локальную сеть с интернетом.
repeaters - усиливают сигнал, передают дальше, чтобы сигнал не затухал.
bridges - может свзять несколько локальных сетей, работают на уровне frame, таким способом уменьшается нагрузка а сеть.

Routing
---

Пакет данных перемещается от источника к месту назначения с помощью router.
• Router отвечает за правильную адресацию в зависимости от объема трафика,
ошибки в сети или других параметров
Routing table кэширует адреса устройств.
Когда IP получает пакет от протокола более высокого уровня, такого как TCP или UDP,
в таблице маршрутизации ищется маршрут, наиболее близкий к пункту назначения.
• От наиболее специфичного к наименее специфичному маршруту идет следующий порядок:
• Маршрут, соответствующий IP-адресу назначения (маршрут хоста).
• Маршрут, который соответствует идентификатору сети IP-адреса назначения (сетевой
маршрут).
• Маршрут по умолчанию.
• Если соответствующий маршрут не найден, IP отбрасывает пакет.

IP services
----

Fragmentation, timeout, options

Fragmentation - возможность деления на более маленткие части

timeout - ограничение на количество узлов, которые может посетить пакет

options - можно установить требования при посылки, например отследить узлы посылки

Socket
----

Сокет — это конечная точка канал связи, используемый программой для передачи данных туда и обратно локально или через Интернет.

![image](https://user-images.githubusercontent.com/79725120/213431729-8cd76ab4-e8c7-429c-b627-b964b588a4b2.png)

![image](https://user-images.githubusercontent.com/79725120/213431822-61b5b11b-88bb-4394-bf5f-f244df441926.png)
  
Сетевой стек в Линуксе
---
  
  ![image](https://user-images.githubusercontent.com/79725120/213433410-c2da8749-0f28-49cf-bc95-0efdecc3c6bf.png)


## Лекция 10
______
Распределенные системы. Оверлейные сети. Понятие middleware. ОС и middleware. Цели дизайна распределенной ОС. Ошибочные предположения в дизайне распределенной системы. Высокопроизводительные распределенные системы. Кластерные архитектуры. Grid-архитектуры. Облачные архитектуры. Проникующие системы (pervasive systems). Вездесущие (Ubiquitous) системы.

Распределенные системы - набор автономных независимых элементов, которые для пользователя образуют цельную систему, они не видят ее структуры. Нет условий для частей системы, они могут быть высокопроизводительный. Также нет условий для связей астей. Изначально распределенную систему придумали для обмена сообщений(они могут быть сколь угодно большими). Потом обнаружилось, что на распределенный системах вычисления работают намного бытсрее.

Централизованная система - одна компонента, отличие в том, что части не могут работать по одиночке. Компьютер, телефон не являются распределенной системой.

Проблемы при организации распределенный систем
___________

1. отсутсвует общий глобальный временной механизм. Подключение к вай-фай работает в периодическом режиме, но создается впечатление, что он работает постоянно. история про apple, инженеры придумали, как можно максимальное количество устройств с одинаковой частотой бахнуть и это было наиболее энергоэффективно.
2. как упрявлять членством узлом во множеству, нужно реализовать процедуру регистрации. Есть открытые или закрытые(например, банкоские системы). Механизм аутентификации.

Оверлейные сети
----

Узел оверлейной сети — это программный процесс, оснащенный списком другихпроцессы, которым он может напрямую отправлять сообщения.
• Затем передача сообщений осуществляется по каналам TCP/IP или UDP.
(sockets). Также могут быть доступны средства более высокого уровня и более эффективные.

Обычно существует два типа оверлейных сетей:
1. Структурированное наложение: каждый узел имеет четко определенный набор соседей, с кем он может общаться. Например, узлы
организованы в виде дерева или логического кольца.
2. Неструктурированное наложение: каждый узел имеет ряд ссылок на
случайно выбранные другие узлы.
• Узлы в оверлейной сети всегда должны быть подключены
• всегда существует канал связи, позволяющий любым двум узлам маршрутизировать сообщения от одного к другому.
Пример: (P2P).

Middleware - еще один уровень программного обеспечения, который находится между ос и приложением(еще один уровень поверх ядра).
![image](https://user-images.githubusercontent.com/79725120/213441619-d9814705-7f3c-4738-a1a7-d234b4d74113.png)

Сетевой стек раньше был middleware, но потом ушел в ядро. 

Middleware & OS
Промежуточное ПО — это менеджер вычислений, хранения и сетевых ресурсов. Предлагая приложения для эффективного совместного использования и развертывания этих ресурсов в распределенной системе
Наряду с управлением ресурсами он предлагает услуги, которые также можно найти в большинстве ОС, в том числе:
• Средства для связи между приложениями.
• Охранные сервисы.
• Бухгалтерские сервисы.
• Маскировка и восстановление после сбоев.

Типичные мидлвэир сервисы
----

communication - удаленный вызов процедурю. Вызывающий процесс упаковывает операцию, этот пакет передается в ядро. Потом пакет передается в нужный процесс.
transaction - целостное действие, которое мы просим выполнить у другого процесса, либо получаем ответ, либо получаетм ничего.
serve composition - машап (информация из разных источников) в одном месте
reability - сообщение гарантированно будет послано одному из узлов

Цели дизайна распределенной ОС
----

1. Поддержка для совместного пользования ресурсами TCP - хорошая продвижка, общий протокол
2. Сделать незаметным факт распределенности. 
Репликация - есть сервис ютуба, как сделать быстрый доступ. Например, сделать дубликаты на локальные сервера.
Польностью прозрачными нельзя сделать все аспекты. 
![image](https://user-images.githubusercontent.com/79725120/213446524-464b35da-3f66-4057-9499-fda6253ebb74.png)
Можно сделать более понятным, что существует непрозрачность.
3. Открытость
Совместимость, компонуемость и расширяемость
• определять сервисы через интерфейсы, т.е. использование языка определения интерфейса (IDL)
• необходимость изменения распределенной системы часто вызвана компонентом,не обеспечивает оптимальную политику для конкретного пользователя или приложения
• разделение между политикой и механизмом
4. Маштабируемость
Когда распределенная система может увеличиваться и уменьшаться. scalable - вставляем в сревер диски большего объема scalout - ставим рядом еще один сервер.
Можем увеличивать географический охват
Администрированная масштабироемость -  это система, которой легко управлять даже если он охватывает множество независимых административных организаций.
5. Производительность
latency - интервал времени, можем замерить с помощью пинга
throughtput - гигабайты в секунду, скорость передачи данных
6. Надежность
Определяется вероятностью поломки
Можно обеспечить за счет избыточности.
7. Безопасность
Защита от дудос атак, от утечке данных
9. конкурентность, управляемость, разнородность

Проблемы с распределенной системы 
Network, nodes, SW are reliable
Не надо рассчитывать на надежность, система скорее всего перестанет работать, если слрмается какая-то его часть.
Network, nodes, SW are secure
Не нужно рассчитывать на безопасность, нам рассказывали про то что у интеля есть возможность отключить все процессоры.
Network, nodes, SW are homogeneous
Если мы хотим при поломке заменить
The topology does not change
Если перенести сервер, то все сломается
Latency is zero
не всегда
Bandwidth is infinite
Transport cost is zero
one administrator


Виды систем
----

Cluster computing
есть главный компьютер, он соединяется по обычной сети, локальные узлы по локальной сети
![image](https://user-images.githubusercontent.com/79725120/213449867-99fe144c-ad23-4d3f-85b5-9cfb32332b8d.png)

Grid
----

![image](https://user-images.githubusercontent.com/79725120/213449989-5b9333f8-089a-42a1-b049-638c2cfcee74.png)
Ресурсы из разных организаций объединяются, чтобы позволить сотрудничество группы людей из разных учреждений, образуя объединение систем.

Cloud 
----
![image](https://user-images.githubusercontent.com/79725120/213450327-24aa117b-87f3-4507-a7d8-0811c7b3dedf.png)

Аппаратное обеспечение: Нижний уровень формируется средствами управления необходимым аппаратным обеспечением:
процессоры, маршрутизаторы, а также системы питания и охлаждения. Обычно это реализуется в центрах обработки данных
и содержит ресурсы, которые клиенты обычно никогда не видят напрямую. • Инфраструктура. Это важный уровень, формирующий основу для большинства платформ облачных вычислений.
Он использует методы виртуализации, чтобы предоставить клиентам инфраструктуру, состоящую из виртуальных
хранения и вычислительных ресурсов. Действительно, все не так, как кажется: облачные вычисления развиваются вокруг
выделение и управление виртуальными устройствами хранения и виртуальными серверами. • Платформа: разработчику приложения предлагается специфичный для поставщика API, который включает вызовы для загрузки
и выполнение программы в облаке этого поставщика. В некотором смысле это сопоставимо с семейством Unix exec.
системных вызовов, которые принимают исполняемый файл в качестве параметра и передают его операционной системе для обработки.
казнен. Как и операционные системы, уровень платформы обеспечивает абстракции более высокого уровня для
хранилище
• . • Приложение. На этом уровне запускаются фактические приложения, которые предлагаются пользователям для дальнейшей настройки.
Хорошо известные примеры включают те, которые можно найти в офисных пакетах (текстовые процессоры, приложения для работы с электронными таблицами,
приложения для презентаций и так далее). Важно понимать, что эти приложения снова
выполняется в облаке поставщика. Как и прежде, их можно сравнить с традиционной сюитой
приложения, поставляемые при установке операционной системы.


Проникающие системы - проникает в наше окружение
----
Например система умного дома. Есть сенсоры и актуаторы(пылесос, кондиционеры)

Вездесущие системы
----
нельзя выключить, например спутниковая система, рассчитывающая геолокацию. С ними можно взаимодействовать неявным образом. Например, хочу включить сбор частоты сердца. Не требует вмешательства человека

Ad hoc системы
----
Например 2 телефона могут соединиться без использования датацентров.



### Лекция 11
Мобильные ad hoc системы. Концепции архитектуры распределенных систем. Архитектурные стили для распределенных систем. Объектные архитектуры. Распределенные и удаленные обьекты. Ресурсно-ориентированные архитектуры. Архитектура Издатель-Подписчик. Структурированные peer-to-peer системы. Неструктурированные peer-to-peer системы: обмен сообщениями. Иерархические peer-to-peer системы.

Мобильные ad hoc системы
----
Проникающая системы, 2 устройства можно объединить и обмениваться файлами. Нельзя сделать такое с большим количеством устройств, функциональность ограничена. Так как устройства перемещается, то оно может переместится настолько далеко, что выпадет из системы

Свойства:
1. Положение может менятся со временем
2. Устройства разного типа(пульт управления, что угодно).
3. Вмешательсво человека не требуется для настройки.
4. роутеры, все статические узлы не используются, так как, как правило, неустойчивы, поскольку узлы на пути маршрутизации могут легко выйти из диапазона соседа, что делает путь недействительным.
5. Такая система не используют заранее установленную инфраструктуру(роутеры, точки доступа)
6.  Тогда каждый узел участвует в маршрутизации, каждое устройство "роутер".

2 принципа
1. Если узлу нужно передать другому, то он может передать всех. Либо нужному, либо тому, кто может
2. Когда промежуточный узел получает сообщение, хранит полученное сообщение до тех пор, пока не встретится с другим узлом, которому он сможет его передать. Узел становится временным носителем сообщения.

Концепции архитектуры распределенных систем
Распределенные системы часто представляют собой сложные части программного обеспечения,
компоненты по определению рассредоточены по нескольким машинам. Чтобы справиться с их сложностью, крайне важно, чтобы эти системы были организованные. Организация распределенных систем в основном связана с программным обеспечением компоненты, из которых состоит система.
• Архитектура программного обеспечения

Компонента - модуль, единица трансляции, которую можно заменить. Приложение как компонента может быть перезапущена на ходу. Также хорошо, чтобы была реализована возможность, в которой компонента бы не работала и ничего не сломалось бы.

Коннектор - механизм, обеспечивает связь компонент.

Архитектурные стили для распределенных систем
----

1. Слоеная архитектура (Layered architectures)
2. Делается в терминах объектов(Object-based architectures)
3. ресурсы ( Resource-centered architectures)
4. события (Event-based (Publish-Subscribe) architectures)

Layered architectures
----

![image](https://user-images.githubusercontent.com/79725120/213586723-2766164d-a4e3-4527-9110-d8316b82bae0.png)

а) Строгая иерархия слоев
б) Нестрогая
с) Можно делать вызовы из верхнего в нижний и наоборот(upcalls)

Объектные архитектуры
----
Состоят из объектов разного уровня сложности в нужном порядке. 

![image](https://user-images.githubusercontent.com/79725120/213587099-06b0f89f-99c0-4231-ae9b-aaaab5fd6491.png)

Распределенные и удаленные обьекты
----

А что если объекты расположены на разных машинах. Помогают proxy sceleton
![image](https://user-images.githubusercontent.com/79725120/213587486-ffb64f26-1770-4ca3-b8fa-7ba22b26fcb3.png)

На клиентской машине создается proxy, кусок куда с таким же интерфейсом, как и у объекта с удаленной машины. Если Обращаемся к нему, то идем в скелетон на серверной машине и он уже вызывает нужный метод. А программе кажется, что мы просто вызвали объект.


![image](https://user-images.githubusercontent.com/79725120/213587870-e04d451a-b4b6-48ea-9f4f-aedb425ad02a.png)

Нужно понять, что такое враперы и брокеры

Ресурсно-ориентированные архитектуры
----

Есть возможность для удаленных приложений пользоваться архитектурами. Есть 4 операции PUT POST GET DELETE. У всех сервисов одинаковый интерфейс.

Архитектура Издатель-Подписчик
----

![image](https://user-images.githubusercontent.com/79725120/213588634-007497bf-1236-44df-92ff-3f5d571283e5.png)

Есть разнообразные компоненты, которые взаимодействуют друг с другом и общаются с помощью событий.
События 2 типов
1) Публикование
2) Подписка

Когда публикуется, подписываемая компонента должна быть активна в варианте а
В варианте б есть место, где хранятся все сообщения.

Детали:
Подписываться можно на интервал значений, или на одно.

Процесс, который занимается переносом сообщений, он может пинговать всех, а может иметь хэш- таблицу с подписчиками.

Также у сообщения может быть срок жизни, после которого он умирает.

Структурированные peer-to-peer системы
---- 
Можно поддерживать какую-то таблицу, которая будет поддерживать список подписчиков.

![image](https://user-images.githubusercontent.com/79725120/213589580-794c3d4b-72a8-4491-836d-9ba2dd8199ea.png)
![image](https://user-images.githubusercontent.com/79725120/213589782-0a4ab372-2497-4c77-9b91-15ffa8169d01.png)
избранные узлы соединены друг с другом, отвечают за все узлы, которые меньше них, промежуточные узлы могут добавлятся или удалятся


Неструктурированные peer-to-peer системы: обмен сообщениями
----
Вероятность наличия ребра между двумя узлами одинаковы. Когда какой-то узел присоединяется, ему нужно связаться с каким-то известным узлом, например к днс-серверу. Нет гарантии, что узлы будут жить, и как будут присоединяться.

Иерархические peer-to-peer системы.
----
Есть избранные узлы.
В новых системах поиск соответствующих элементов данных может стать проблематичным по мере роста сети.
Причина этой проблемы с масштабируемостью проста: поскольку не существует детерминированного способа маршрутизации запроса поиска к конкретному элементу данных, по сути, единственный метод, к которому может прибегнуть узел, — это поиск запроса с помощью флуда или случайное блуждание по сети.

В качестве альтернативы многие одноранговые системы предлагают использовать специальные узлы, поддерживающие индекс.
элементов данных. Существуют и другие ситуации, в которых отказ от симметричной природы одноранговых систем является целесообразным.
разумный. Рассмотрим сотрудничество узлов, которые предлагают ресурсы друг другу.
• Что необходимо, так это способ выяснить, где лучше всего хранить документы. В этом случае, используя брокера
который собирает данные об использовании и доступности ресурсов

![image](https://user-images.githubusercontent.com/79725120/213590277-60a95089-745a-44f7-99da-e9170efc689e.png)
пример иерархической системы, но не структурированной, потому что к любому избранному узлу могут подключаться любое количество обычных узлов.

## Лекция 12
21.Планирование ресурсов в ОС. Планировщик процессов. Типы планировщиков (по горизонту планирования). Диспетчер процессора/процессов. FIFO планировщик. Метрики планирования в мобильной ОС.

• Планирование CPU
• Планирование ввода-вывода
• Сетевое планирование
• Планирование памяти
• Планирование заданий (общий термин, относящийся к мейнфреймам, исторический

Датацентры потребляют очень много энергии. Зеленая повестка обманывает

Планирование ресурсов в ос - работа различных алгоритмов, которые ограниченное количество ресурсов распределяют по приложениям.

Когда данные читаются, приложение ничего не делает на процессоре, разумно отдать это время процессорное другому приложению.

Планирование выполняется планировщиками sheduler. Есть много планировщиков, например ввода-вывода. Намного проще разрабатывать отдельные планировщики по методы разделяй и властвуй. Однако если они не знают друг про друга, то они работают намного менее эффективно. были попытки сделать один глобальный планировщик, но до сих пор в ос планировщики специализированы(фукнкц разделена)

Цели
----
1. максимизация скорости вычисления
2. минимизация задержек
3. максимизировать справедливость распределения(либо поровну, либо делить так, что наиболее важная получала больше ресурсов)
4. минимизировать затрату батарейки

Часто цели конфликтуют

Ряд абстракиий планирования
----

Дисциплина планирования 
----

Часто планировщик выбирает несколько сценариев в зависимости от поведения пользователя. В одном случае алгоритм пытается минимизировать задержки, в другом случае минимизировать расход батареи. Например, когда мы в телефоне включаем режим экономии, то у нас по сути включается другой планировщик. И некоторые задачи будут выполняться например с большими интервалами.

Планирование ресурсов
----
несколько подходов
1. как используются устройства, планирование процессов
2. либо планирование задач

Планирование процессов
----
Еще одна группа алгоритмов, которые решают, в какой момент времени, какой процесс будет работать и какие задачи выполнять.
Планировщик процессов может останавливать процессы. Прием вытеснения из памяти процесса.
Процессы зависят от пользовательского ввода, железа и тд. Поэтому при планировании важно собирать статистику о работе приложения, сбор помогает существенно.

Тогда можем классифицировать приложения:
1. CPU bound - узкое место процессор, например вычисление матриц, вычисление числа пи
2. memory bound - опять же матрицы
3. IO bound - обработка баз данных, ввод вывод на диск
4. network bound - браузер

Типы планировщиков (по горизонту планирования)
----
1. Долгосрочные ( сервера)
2.  Среднесрочные
3.  Краткосрочные (мобильный телефон)

Долгосрочные планировщики
----

Планируют как правило такие операции, которые используют или очень много ввода-вывода, или очень много вычислений. Долг планировщики затощены на то, чтобы предугадывать, сколько задачам нужно времени ввода-вывода

Среднесрочные
----

Смесь между двумя. Оптимизированы, чтобы память каких-то приложений вытеснять на диск, а потом записывать. Если приложение какое-то время неактивно или низкий приоритет, или часто падают странички, если приложение занимает много памяти. 

Краткосрочные
----

Частота планирования существенно выше, следовательно время планирования нижу, чтобы операция чаще и быстро могла совершаться, милисекунды. Сбор почти никогда не применяется. Вариант выгоднее, это когда данные загружеются, отправляются на сервера, на них обучается нейронка, а потом загружается в телефоны опять.

Диспетчер - часть планировщика, работает в ядре
----

Диспетчер — это алгоритм, который передает управление ЦП процессу, выбранному краткосрочным планировщик. Происходит переключение контеста, сохраняется состояние процесса, загружает процесс, который надо загрузить. Передает на точку программы, с какого момента надо начать программу. Оно должно происходить быстро. Так как во время переключения проццесор и ядра процесссора ничего не делают. В айфонах почти все время работает 4 потока, в то время как на андроиде 100, поэтому планировка происходит проще и раскладывание по 4 ядрам тоже.

FIFO планировщик - First in, first out
----

Просто по сути очередь, не самый умный. В операционных системах не используется, но в некоторых приложениях - да. 
Например есть 8 потоков, одна очередь, тут нам надо задуматься о параллельности, например с мьютексами, но это не очень высоко в происзводительности. Если считаем, что порядок не очень важен, то мы можем завести 8 очередей, в которые потоки-исполнители складывают информацию, а поток потребитель забирает. 

Если каждому процессу, который сложили в очередь дать определенное время, за которое он должен отработать, то тогда каждый процесс через определенное назначенное время попробует отработаться. Круто

Если вводим понятие приоритета, то можно с большим приоритетом складывать в начало.

![image](https://user-images.githubusercontent.com/79725120/213691207-07cee459-9b03-40b8-8f21-b31ee468260d.png)


Метрики планирования в мобильной ОС
----

1)IPC - instructions per cycle

раньше проццесор был тем лучше, чем больше у него частота, но она мало говорит. Нужно количество испольненных инструкций за один цикл. 

IPC зависит от многих факторов: количества ядер ЦП, частоты ядер ЦП, количества, конвейеры ядра ЦП, планирование инструкций по порядку и не по порядку (спекулятивное) ЦП, задержка памяти, кеши SoC, алгоритм планирования ОС для многозадачности. ОТ программы и от компилятора, так как он может выстраивать их в параллельные штуки

Как мы можем выполнить 2 задачи за такт? Если у нас есть несколько конвееров для выполнения, на каждом выбираем инструкцию, они могут никак не зависеть друг от друга, например одна читает какую-то информацию, другая вычисляет что-либо, поэтому выполняем параллельно, так как в программах много последовательных инструкций, не связанных друг с другом.

Конвееры специализированные, одни для логических операций, другие для арифметических, третьи для даблов.

 2)DPC - Dynamic power consumption
 
• Статическое энергопотребление (мощность, потребляемая аппаратным обеспечением без выполнения задач) выходит за рамки нашего интереса
• DPC напрямую связан с разрядкой батареи в мобильных устройствах, разрядкой мощности центра обработки данных
• DPC измеряется в ваттах (джоулях в секунду, другими словами - производная работы по времени)
• DPC напрямую зависит от количества циклов ядра ЦП, затраченных на выполнение задачи, а также от мощности потребление другими устройствами, например. энергонезависимая память, сеть и т. д.
• Более высокий показатель IPC означает, что больше инструкций может быть выполнено при том же или более низком DPC.

Минимизация производственного цикла – классическая метрика в планировании.
----

Что может сделать планировщик мобильной ос?
Может быстренько собрать статистику о прерываниях, об их времени работы. И исходя из него распределяются задачи по потокам.

***Билет 22*** Абстракции/концепции планирования. Абстракция/концепция аппаратуры/»железа»/устройства для планирования. Абстракция/концепция задачи/процесса для планирования.

Абстракции/концепции планирования
----

1)Статическое - информация о приложении заранее известна, оно всегда вполняет последовательные действия, поэтому что-либо планировать для него легко.
2)Динамическое - мы только сможем оценить вероятность какого-то действия
3) Preemptive and non-preemptive scheduling - мы можем останавливать/убивать приложения, или нет. Более выгоден вариант с убийством.
4) Hard real-time and soft (non-) real-time scheduling - реальное время, значит до мы должны делать действия до дедлайна.
5) Partitioned and global scheduling
Разделенное - есть ядра у процессора, у каждого своя очредеь, мы ее выстраиваем, передаем каждому ядру свою задачку. 
6) Миграция статических задач — разделение задач осуществляется разработчиками,  снимается с планировщика немножко работы. (перед выполнением): некоторые задачи выделяются только одному ядру, в то время как другие
выделено более чем одному ядр
7) Dynamic workload balance – run-time migration of tasks ( разделеине задач в рантайме, ядра не обязаны быть из одного кластера)
8) Кластерное планирование, ядра разделены на кластеры. Каждый кластер планирует свои задачи независимо

![image](https://user-images.githubusercontent.com/79725120/213696091-f7c63b2f-4516-4fdf-9727-017641f628b0.png)
![image](https://user-images.githubusercontent.com/79725120/213696122-4d724ecb-d2cc-4e72-a46e-2adbf0288329.png)

![image](https://user-images.githubusercontent.com/79725120/213697074-d95b0909-c64a-42b6-a690-8f257453adfd.png)


Большое приложение уже разбито на маленькие задачи

Абстракция/концепция аппаратуры/»железа»/устройства для планирования
----
В зависимости от процессора планируем
![image](https://user-images.githubusercontent.com/79725120/213698691-9cf9d609-861b-4d23-a182-7ee297e39267.png)
Тут показан один из вариантов, когда есть хайповые большие проццесоры, которые делают более затратные операции, умеют выполнять не по порядку и менее хайповые.
Каждый кластер работает на независимой частоте,а все ядра в кластере работают на одинаковой. У каждого процессора свой кэш, у каждого кластера свой кеш. И это все связано через 128 битную шину.
1) 

Абстракция/концепция задачи/процесса для планирования
----
• новые задачи могут быть добавлены в любое время, старые задачи могут быть удалены в любое время
• каждая задача может быть запущена в произвольное время
• у каждой задачи могут быть требования к реагированию на внешние события (например, в пользовательском интерфейсе) • Установите T из |T| задачи, индексированные как t[1..|T|]: T = {t[1],…t[|T|]}
![image](https://user-images.githubusercontent.com/79725120/213704419-3ed9428f-9b15-4718-8b89-1a9cd0d2a66e.png)


Кэши могут быть запланированы на задчи и задачи на кэши.

## Лекция 13

***Билет 23.***.История планировщиков в ядре Линукс. Планировщик CFS. Планировщик процессоров/процессов и формулы потребления энергии. Потребление энергии процессором/памятью. Абстракции управления потреблением энергии.

***Билет 24***.Что такое DVFS, зачем оно нужно. Архитектура big.LITTLE в контексте планирования процессов. EAS — что это такое, основные принципы. Отслеживание нагрузки для планирования процессов. EAS PELT/WALT. C & P, CC & PC состояния процессора. Управление P состояниями со стороны ОС. Масштибирование производительности в ядре Линукс. Управление частотами в ядре Линукс. Что такое CPUFreq, CPUIdle и гувернеры.

1. очень простой планировщик на основе циклической очереди (Round-Robin)
2. Linux 2.4: планировщик O(n)
 Разделить процессорное время на эпохи. В каждой эпохе каждая задача может выполняться до своего кванта времени. Если задача не использует весь свой квант времени, то планировщик добавляет половину оставшийся временной отрезок, чтобы позволить ему выполняться дольше в следующей эпохе.
3. Linux 2.6.0 — Linux 2.6.22: планировщик O(1)
Каждому процессу дается фиксированный квант времени, после чего он вытесняется и
перемещен в просроченный массив. После того, как все задачи из активного массива исчерпали свой квант времени и
были перемещены в массив с истекшим сроком действия, происходит переключение массива. Поскольку доступ к массивам осуществляется только через указатель, переключение между ними происходит максимально быстро.
поменять местами два указателя. Этот переключатель делает активный массив новым пустым с истекшим сроком действия.
массив, в то время как массив с истекшим сроком действия становится активным массивом
4. Linux 2.6.23 (2007 г.): полностью честный планировщик. BFS (2009 г.) как альтернатива CFS
6. Linux/Android (2013+): начато обсуждение EAS.
7. Android (2017 г.): планировщик ядра 4.4–4.9 Energy Aware.
8. Linux 5.x (2022 г.):пдгодит для гетерогенных процессоров EAS это скедулер

Планировщик CFS
----

Используется красно-черное дерево. Задача либо крайнем левом, либо в крайнем правом. Сортируем по тому, насколько задача использовала процессор. Чем меньше занимала, тем больше приоритет.

Планировщик процессоров/процессов и формулы потребления энергии.
----

Если например задача требует много вычислительных ресурсов, то нужно ее испольнять на наиболее энергозатратном ядре. И наоборот. И по-разному использовать батарейку.

Чем выше частота, тем больше тратится энергии.

тут опять про биг литтл кластер
![image](https://user-images.githubusercontent.com/79725120/213864685-7479ac0b-a8f8-44cc-b4f6-317e189171ba.png)

Мобильные устройства получают энергию, необходимую для работы, от батарей, емкость которых ограничена.
по размеру устройства.
• Способность управлять энергопотреблением требует хорошего понимания того, где и как используется энергия.
• Расширение функциональности современных смартфонов увеличивает нагрузку на срок службы батареи и увеличивает потребность в эффективном управлении.

![image](https://user-images.githubusercontent.com/79725120/213864764-fb36c4e3-71c1-4522-8db3-e939a5d5b0df.png)

Формулы, которые использует планировщик
----

мощность = сила тока * напряжение
энергия = мощность * время
батарейка (5000 мили ампер) = сила тока * время * напряжение - время, которое есть в батарейках
мощность( динамическая) = частота * емкость * напряжене в квадрате + статическая мощность(мощность короткого замыкания + мощность утечки)

Напряжение и частота всегда изменяются вместе

Потребление энергии процессором/памятью.
----

Потребляемая мощность зависит от частоты, на каждый цикл(колебание) одна и та же мощность, но в зависимости от того сколько циклов в секунду изменяется кол-во потребляемой мощности.

Зачем планировать, как работает процессоры, так как например камера потребляет в 3 раза больше энергии. Камера - эпизодически. А проццессор работает всегда.

![image](https://user-images.githubusercontent.com/79725120/213865013-ec3d133b-4c8c-409b-9416-418b11132193.png)

Dynamic Voltage and Frequency Scaling
---
 Совместное изменения напряжения и частоты. Если изменить частоту, не меняя напряжения, то с телефоном произодет беда(кирпич). Функция, которой пользуется планировщик. 
 
Используется практически во всем современном компьютерном оборудовании для максимального энергосбережения.

Отслеживает рабочую нагрузку, определяет правильные настройки напряжения и тактовой частоты и соответствующим образом настраивает оборудование.

Например, неиспользуемый смартфон должен вернуться в режим пониженного энергопотребления, исключая помехи от
приложения. 

Для мультимедиа требуется больше энергии, поэтому устройство переходит в режим более высокого энергопотребления и выделяет больше тепла. во время более тяжелой обработки, такой как видео и игры. 

Если бы не DVFS, многим устройствам с пассивным охлаждением потребовалось бы активное охлаждение. Однако, шум, объем и потребляемая мощность, необходимые для активного охлаждения, делают его непрактичным для небольших устройства. 

DVFS помогает поддерживать рабочие параметры при повышенной мобильности.

![image](https://user-images.githubusercontent.com/79725120/213865475-b66b9329-4bff-4d86-b8ea-ec7fd04d1cfb.png)

Dynamic Power Management (DPM) to manage power in core idle state (состояние, в котором потребляется мало энергии) - not in our area of interes. f state - formale state (обычное), s(си) state (состояние сна)


Абстракции управления потреблением энергии.
----

Может оказаться, что процессор слишком быстро вычисляет данные, и данные из памяти не успевают вытаскиваться -> тратится много энергии, можно понизить частоту.

![image](https://user-images.githubusercontent.com/79725120/213865621-d21b89af-5625-4088-a202-50067a811ae1.png)

чето типо теперь после понижения на память потратится только 2 такта, хз почему

Архитектура big.LITTLE в контексте планирования процессов
----

Главное - постановка задачи. Неправильное распределение ядра задач сводит на нет преимущества big.LITTLE.

big.LITTLE предъявляет высокие требования к планировщику
 1) Следует знать о 2-х(или 3ех) типах ядер
 2) Он должен учитывать энергию
 3) он должен взаимодействовать с подсистемой DVFS


Планирование big.LITTLE подразумевает, что планировщик умеет предсказывать потребности задач. Для аппаратной части это не требуется, потому что происзводитель опубликовал все данные изначально, планировщик ими пользуется. Про железо все известно, а на программ спецификаций нет( Что-то трудно предсказать о пользователях. А быстрому планировщику не дл нейронок.

CFS — хороший планировщик. Но это не совсем то, что нужно для big.LITTLE.
• 
• Работа началась еще в 2013 году. Расширение возможностей CFS для применения к архитектурам, отличным от SMP для гетерогенных  архитектур.
Разработаны 2 конкурирующие реализации
![image](https://user-images.githubusercontent.com/79725120/213866007-ee5debf0-0573-4473-a26a-6a1e5aeb8769.png)

EAS
----

Решение должно приниматься на основании:

1) Топология, сколько кластеров, сколько ядер в кластерах(симметричное нессиметричное)
2) Расход энергии
3) Рабочая нагрузка для каждого ядра 
4) Функции управления питанием
5) CPU Idle states, DVFS

Цель : минимизировать энергию, но чтобы пользователь был удовлетворен. ТО есть хоти максимизировать performance (ipc) / power(Watt)

Использует Energy Model для выбора подходящего ядра

1) по сути интерфейс или фреймворк между драйверами, которые знают как потребляется энергия разными ядрами и подсистемами ядра
2) учитывает только затраты процессора, а не вай-фай и другие переферийные устройств.

когда задача пробуждается используется енерджи модель ( учитывается статистика + характеристики аппаратур + емкость (кол-во вычислений процессора)) самый хайповый - 100 процентов и остальные по нему

Категорезирует скедулер на 4 группы being top-app (юзер интерфейс, так как ожидается, что срабатывает моментально, максимальный приоритет), systembackground, foreground, and background. 

Если задачу пробудилась, все занято, а остальные спят, то нужно пробудить самое некрепко спящее, чтобы заьтратить на это меньше времени. Подъем частоты тоже тратит энергию, пока мы дождемся пробуждения\ перехода, то было бы более эффективно на уже проснутых ядрах.

Отслеживание наргузки
----

критическая часть
Load tracking is also an extremely crucial part of EAS, this information is used to decide 
frequencies and how to delegate tasks across the CPU, and there are two options:
• "Per-Entity Load Tracking" (PELT) (для каждого ядра)
• "Window-Assisted Load Tracking" (WALT) 

EAS PELT/WALT
----

Отслеживание нагрузки: что и зачем
1. LT предназначен для отслеживания потребности в задачах (нагрузки) и загрузки ЦП.
1)Классификация задачи как «тяжелой» в случаях использования в мобильном мире, таких как прокрутка пользовательского интерфейса или просмотр веб-страницы.
где задачи проявляют спорадическую большую нагрузку
2)Также важна переклассификация легкой задачи в тяжелую — например, поток рендеринга может изменить свою
спрос в зависимости от того, что отображается на экране
2. Балансировка нагрузки
3. Размещение задач. Отслеживание загрузки задач и использования ЦП необходимо для планирования с учетом энергопотребления. Тяжелые задачи могут быть размещены на процессорах большей мощности. Небольшие задачи могут быть упакованы на загруженном процессоре без пробуждение бездействующего процессора.
5. Руководство по частоте
6) Регулятор частоты процессора (schedutil, powersave, ondemand и т. д.) управляет повышением и понижением частоты процессора.
его частота в соответствии со спросом.
2) Регуляторы частоты ЦП, такие как по требованию, используют таймер и вычисляют время занятости ЦП, вычитая
Время простоя процессора от таймера

PELT - реагирует более плавно. • Более высокая загрузка ЦП требует более высокой частоты, поэтому характерной чертой PELT является то, что он заставляет частоту ЦП медленно увеличиваться или уменьшаться.

Разработан давно, работает вмесет с cfs, помогает раскидывать задачки. Он учитывает тоот момент, когда не работает процесс. Берем количество периодов, наиболее дальний меньше всего влияет. Даже если задача заблокирована, она учитывается в этом расчете, чем дольше задача заблокирована, тем меньше суммарная нагрузка.

![image](https://user-images.githubusercontent.com/79725120/213867289-15ecefa9-88af-4664-b157-a118b4d7aa02.png)
Берем предсказанную нагрузку, и пихаем
![image](https://user-images.githubusercontent.com/79725120/213867314-b4633e23-d111-4cda-a1e0-d1aaadc5dbe4.png)
тут умножение

WALT - чаще используется, потому что быстрее реагирует на изменение. Не влияет на частоту процессора, он просто сообщает системе, что используется в данный момент.

потребность адачи  = интервал времени * текущая частота / максимальную частоту
вычисляется средняя потребность в этих окнах

Окна, в которых задача не выполнялась, игнорируются и не записываются.

Окна существуют только тогда, когда задача находится в очереди на выполнение или выполняется. Это позволяет быстро переклассификация той же задачи в тяжелую после короткого сна.

Задаче не нужно многократно исполняться, чтобы набрать себе вес.

Волт забывает про задачи как только они ушли.

![image](https://user-images.githubusercontent.com/79725120/213867681-35841c7b-c3f6-4bdc-ade4-1eca4c51d444.png)

![image](https://user-images.githubusercontent.com/79725120/213867701-8bb55b34-a406-45a1-b084-66838f62469a.png)


## Лекция 14, в тетрадке есть

Часть ***23 билета.*** C & P, CC & PC состояния процессора. Управление P состояниями со стороны ОС. Масштибирование производительности в ядре Линукс. Управление частотами в ядре Линукс. Что такое CPUFreq, CPUIdle и гувернеры.


https://www.kernel.org/doc/Documentation/cpu-freq/governors.txt

статья про спи фрег и гувернеров

Есть 2 способа экономия энергии
1) включение выключени
2) увеличение, уменьшение частоты

C & P,
----

Технологии управления питанием процессора определены в спецификации ACPI и делятся на две категории или состояния.

C-state
C + цифра

С0 - нет никакой экономии энергии. Все ядро и компоненты получают энергию. Может тут иметь место P State

P0 - никакая часть не экономит энергию. Максимальная энергия

у арма есть свои состояния, то же что и с р:
1) Standby: ядро остается включенным, но большинство его частотных генераторов остановлены или синхронизированы. Почти все части активной зоны находятся в статическом состоянии. Поэтому потребляется только статическая энергия.
2) Retention: Состояние ядра, включая настройки отладки, сохраняется в режиме пониженного энергопотребления.
конструкции, позволяющие хотя бы частично отключить ядро. Переход от сохранения низкого энергопотребления к рабочему режиму не требует сброса ядра.
3) Dormant mode: основная логика отключена, но кэш-память остается включенной. Цепи ядра выключены, цепи кэша включены.
4) Power down:все цепи обесточены, данные не сохранятся.
5) Hotplug: любой кластер может быть включен\выключен. Горячее вкл выкл

CC & PC состояния процессора
----

стэйты делятся на состояния для ядра и на состояния для кластера

далее делятся на основные C-состояния (CC-состояния) просто ядровые и пакетные C-состояния (PC-состояния).

Причина состояний P-State в том, что в процессоре есть другие (общие) компоненты, которые также могут быть отключены после того, как все ядра, использующие их, будут отключены (например, общий кеш).

• Однако, как пользователь или программист, мы не можем их контролировать, поскольку мы не
взаимодействуем с пакетом напрямую, но мы взаимодействуем с отдельными ядрами.

• Таким образом, мы можем влиять только на CC-state напрямую, PC-state затрагиваются косвенно на основе
на CC-состояниях ядер

![image](https://user-images.githubusercontent.com/79725120/213868800-d9ef84f2-645a-4938-867a-ed2eca9c658c.png)

global - state
slepping - state

![image](https://user-images.githubusercontent.com/79725120/213868957-b46a47df-42e8-4c65-a56f-1c2beaec7006.png)

Состояния Cx можно получить программно.

Планировщик управляет P-State для сохранения энергии. У каждого кластера у всех ядер одинаковое пи состояние, мы не может поменять частоту и непряжение только у одного ядра, нужно у всех!

2 технологии, это цепи
 1) амт
 2) ме
 Можно контролировать удаленно компутер с 2008 года

 Масштибирование производительности в ядре Линукс
 ----

• ОС оценивает требуемую мощность ЦП и решает, в какие P-состояния перевести ЦП.

Действие (НЕ планирование), посредством которого это происходит, называется масштабированием производительности ЦП или ЦП. масштабирование частоты (CPUFreq) - потому что оно включает в себя настройку тактовой частоты процессора


Ядро Linux поддерживает масштабирование производительности процессора с помощью подсистемы CPUFreq.
который состоит из трех слоев кода:
1)основной слой
2) гувернеры - изменяют частоту
3) драйверы масштабирования - общая инфракструктура, как доступаться к масштабированию частоты


• Ядро CPUFreq обеспечивает общую инфраструктуру кода и интерфейсы пользовательского пространства для
все платформы, поддерживающие масштабирование производительности ЦП.
• Регуляторы масштабирования реализуют алгоритмы для оценки требуемой мощности ЦП. Как правило,
каждый регулятор реализует один, возможно параметризованный, алгоритм масштабирования.

Драйверы масштабирования взаимодействуют с оборудованием. Они предоставляют регуляторам масштабирования информацию о доступные P-состояния (или диапазоны P-состояний в некоторых случаях) и доступ к оборудованию для конкретной платформы интерфейсы для изменения P-состояний ЦП по запросу регуляторов масштабирования

Любой гувернер может использоваться с любым драйвером. То есть можно использовать один и тот же алгоритм. Может быть реализовано изменения частоты 
 
 Управление частотами в ядре Линукс. 
 ----
 
 Что такое CPUFreq, CPUIdle и гувернеры.
 ----
 
 Виды гувернеров:
 1)performance - если мы его включаем, ядро будет работать на максимальной производительности, можно задать максимальную частоту
 2) гувернер, который включает сохранение энергии
 3) userspace ничего не делает сам по себе, но позволяет установить частоту из юзерспэйса
 4) ondemand управление частотой процессора, которая учитывает текущую нагрузку
 5) shedutil очень тесно связан с планировщиком. Исполняется в контесте планировщика, вызывает драйвер, при помощи оторого меняется частота. И действия зависит от  планировщика. Гувернер может помочь задаче увеличить приоритет после сна.

CpuIdle
----

каждому процесору ссответсвует структура данных - набор интерфейсом, с точки зрения спю айдл.

1) весь процессор исполняет одну программу
2) многоядерный логический процессор, каждое ядро исполняет одну прогруамму, можем выключать ядра
3) одно ядро несколько программ, мы можем отключать не только ядро, но и отключать вот это задачи на ядрах

цикл 
1) обращение в спю айдл гувернеру
2) вызов модуля драйвера, выполняет перевод в состояние ничего не делания

 на сколько выключено
 время перехода в состояние
 
 Из этих 2ух характеристик понимаем, выгодно ли нам выключать
 
 тики планировщика - прерывания, которые планировщик выдает на ядро. Когда принимаем решение, выключать тики или нет, надо принимать во внимание, в каком состоянии находится ядро. Есть несколько гувернеров для типлесс систем, тех систем, где ядра не получают прерывания в состоянии айдл. они должны быть связаны тоже сильно со шедулером. Гувернеры должны учитывать, что случится прерывание, которое не относится к тикам.
 
 menu: тиклесс
 
 TEO: тиклесс
 
 adder:
 
 haltpoll:


 Лекция 15
----

***Билет 27***.Основы программирования для мобильной ОС. Что такое ADB и как им пользоваться. Измерение производительности приложения в инструкциях и циклах. Что такое perf и как им пользоваться.

Основы программирования для мобильной ОС
----

Цель : только юзер-спэйс
Гарантии: Не сломать телефончик


 Что такое ADB и как им пользоваться.
 ----
 
 Можно с помощью адб удалить пакет, запустить приложение с командной строки и измерить происзводительность.
 Программа, которую можно установить на линукс, нет графических интерфейсов работает с командной строки. Много функций, можно отлаживать приложения.
 
 1)клиент, который подает команды на линукс машине, 
 2)сервер на линукс машине ( посредник)
 3)демон adbd, который уже есть на устройстве
 
 1. Включается режим разработчика
 2. usb debugging
 3. присоединяем телефон через юсб кабель
 4. sudo apt install adb
 5. adb devices -> вернестся какой-то номер 
 
 Измерение производительности приложения в инструкциях и циклах.
 ----
 
 • ginkgo:/$ cat /sys/devices/system/cpu/cpu{0,1,2,3,4,5,6,7}/cpufreq/scaling_available_frequencies
 посмотреть частоту
 от 0 до 7, потому что 8миядерное
 
 • ginkgo:/$ echo 300000 > /sys/devices/system/cpu/cpu0/cpufreq/scaling_min_freq
 установить частоту
 
 Как посмотреть параметры ядра, 
 
 PMU - Performance Monitor Unit(какие-то транзисторные круги, они считают параметры, которые помогут нам определить, насколько хорошо работает наше приложение)
 
 linux-perf - очень простая утилита с командной строки, очень сильно зависит от ядра
 
sudo su –
echo 0 > /proc/sys/kernel/perf_event_paranoid
exit

нужно вот так ее запустить

С помощью перфа можно считать (Hardware perfomance counters) счестчики производительности аппаратуры. Планировщик в ядре использует счетчики эти для своей работы.

набор
регистры специального назначения, встроенные в современные микропроцессоры для хранения подсчетов
деятельности, связанной с аппаратным обеспечением, в компьютерных системах.
1) Расширенное ПО (планирование ядра) часто использует эти счетчики для проведения низкоуровневого анализа или настройки производительности. 
2) Аппаратные счетчики обеспечивают малозатратный доступ к большому количеству подробных данных.
информация о производительности, относящаяся к функциональным блокам ЦП, кэшам и основным
память и др.
3) Еще одно преимущество их использования заключается в том, что не требуется никаких модификаций исходного кода.
в общем.
4) Однако типы и значения аппаратных счетчиков отличаются от одного вида
архитектуры на другую из-за различий в аппаратных организациях
 
 • perf stat –e cycles –e instructions ./hell.x
 
 вот так можно посмотреть
 
 также можно запустить perf в режиме рекорд, чтобы проанализировать на большем промежутке.
 
 ![image](https://user-images.githubusercontent.com/79725120/213896172-198aee1c-dd67-4ac6-a95b-61cb0e0430cf.png)
 
 тут все места, откуда мы можем читать  события
 
 Также можно пользоваться перфом внутри приложения, используя системный код. Одини sysscall позволяет получить много событий.
 

 














 
